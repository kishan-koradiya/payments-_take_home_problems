# Port for the server to run on
PORT=3000

# OpenAI API Key for LLM integration
OPENAI_API_KEY=your_openai_api_key_here

# Environment (development, production, test)
NODE_ENV=development

# Enable/disable LLM features (useful for testing without API calls)
ENABLE_LLM=true

# LLM Cache TTL in seconds (for caching frequent prompts)
LLM_CACHE_TTL=300